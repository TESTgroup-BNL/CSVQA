##Configuration file for CSVQA utlities

[Input]
#File/directory to process
#   Can be overridden with command line parameter
#   Default is all CSV files in current directory
#   Accepts standard wildcards
fpath = ..\data\2018\
inputFile = *.dat
#"*.csv"

#Source characteristics file
#   If path is not absolute, fpath will be used as the base
#   If omitted, general precision rules defined below will be followed
sourceCharsFile = source_characteristics.csv

#Interval of exisitng data
baseFreq = '1Min'

#Row containing column names
headerRow = 1

#Other header rows (will not be processed)
skipRows = [2,3]

dtFormat = "%Y-%m-%d %H:%M:%S"

#Column used as date/time index
indexCol = "TIMESTAMP"

#Columns that should be min-ed instead of averaged in grouping aggregation
timeCols = ('TIMESTAMP', 'RECORD', 'YYYYMMDD', 'HHMMSS', 'Frac_of_Day')

#Columns that should be treated as integers
intCols = ('RECORD', 'YYYYMMDD', 'HHMMSS')

#Columns that should be unique (used to identify duplicates)
uniqueCols = ["TIMESTAMP","RECORD"]

#Value to read as Nans from the input files
inputNans = ["NAN","-999"]



[Level 1]
#Preference for handling duplicate records (all columns):
#   ‘first’ : Drop duplicates except for the first occurrence.
#   ‘last’ : Drop duplicates except for the last occurrence.
#   False : Drop all duplicates.
#   ‘halt’ : Stop proccessing data.
dupRecPref = 'last'

#Preference for handling duplicate timestamps:
#   ‘first’ : Drop duplicates except for the first occurrence.
#   ‘last’ : Drop duplicates except for the last occurrence.
#   False : Drop all duplicates.
#   ‘halt’ : Stop proccessing data.
dupTSPref = 'last'

#Enables automatically comparing one or more fields against an alternate data source
altCheckEnable = True

#Suffix added to data file name to indicate an alternate data source
#The alternate source does not have to have all fields or the same sample rate
altFileSuffix = "_alt"

#Interval to offset alternative data by, represented as a Pandas time interval
altTimeOffset = '0Min'

#Date/time format string for alt data
altDateTimeFormat = "%y-%m-%d %H:%M:%S"

#Deviation threshold
#   Maximum allowed deviation between primary and alternate
#   Represented as a fractional value of the full scale range (max-min) defined in source charateristics
devThreshold = 0.05


[Level 2]
#Intervals to group by
#   An output file will be generated for each interval
freqs = ('30min', '1H', '1D')

#Maximum fraction of records that may be missing from a group mean (0.1 = 10%)
maxMissing = 0.1


[Level 3]
#Intervals to group by
#   An output file will be generated for each interval
freqs = ('30min', '1H', '1D')

#Maximum fraction of records that may be missing from a group mean (0.1 = 10%)
maxMissing = 0.1


[Output]
#Path to save output files
#   "" : same as input (default)
outputPath = 

#Value to use for Nans in the output files
outputNans = "Nan"

#Output precision
#   'original' : use original column precision (maximum from original data)
#   else provide format string (ex: '%0.2f')
outputDecs = 'original'

#Minimum/Maximum output precision
#   Useful when using 'original' above or with repeating decimals in floating point
#   values to include or exclude decimal places to something reasonable
outputDecsMin = 2
outputDecsMax = 6

#Console log level
#   'INFO' : Shows processing steps only
#   'DEBUG' : Shows details of actual data (column summary, duplicate records,
#       missing data stats)
consoleLogLevel = INFO